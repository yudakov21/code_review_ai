# Part-1 
## Key Achievements

  Successfully built a FastAPI application with Redis caching and GitHub/OpenAI integrations.
  Improved performance with Redis caching, reducing redundant API calls.
  Delivered a robust code review API that combines AI capabilities with GitHub data to provide meaningful insights.

 This project is ready for deployment and can be further extended with additional endpoints or features.


## How to Use and Launch the Application

Below is a step-by-step guide to set up, run, and use the FastAPI application.
###1. Prerequisites

Make sure the following tools are installed on your system:

    Docker: Ensure Docker is installed and running.
    Download Docker
    Docker Compose: Comes pre-installed with Docker Desktop.
    Python 3.10 or later: If testing locally without Docker.
    Poetry: For dependency management and environment setup.
    Install Poetry: pip install poetry

### 2. Clone the Repository

Clone the repository to your local machine:

    git clone https://github.com/your-username/review-app.git
    cd review-app

### 3. Set Environment Variables

Create a .env file in the root directory to store environment variables. Use the following template:

Redis configuration

    REDIS_HOST=redis
    REDIS_PORT=6379
    
OpenAI API Key

    OPENAI_API_TOKEN=your_openai_api_key
    
GitHub API Token

    GITHUB_TOKEN=your_github_personal_access_token

Replace your_openai_api_key and your_github_personal_access_token with your actual API keys.
### 4. Run the Application with Docker

Build and start the application with docker-compose:

    docker-compose up --build

Verify that the containers are running:

    docker-compose ps

You should see two services:

    review_app: The FastAPI application.
    redis: The Redis caching server.

Access the application at:

    http://127.0.0.1:8000/docs: Interactive API documentation (Swagger UI).
    http://127.0.0.1:8000/redoc: Alternative API documentation.

### 5. Run Locally (Without Docker)

Install Dependencies: Use Poetry to install all required dependencies:

    poetry install

Set Environment Variables: Make sure the .env file is properly configured (Step 3).

Run Redis Locally: If Redis is not already running, start it on your machine. You can use Docker:

    docker run -d -p 6379:6379 --name redis redis:7

Start the Application: Run the FastAPI application:

    poetry run uvicorn main:app --host 0.0.0.0 --port 8000

Access the Application: http://127.0.0.1:8000/docs
    
# Part-2 - What if

## Handling Large Repositories with 100+ Files


### Asynchronous Programming:

  Using asyncio and non-blocking I/O in the backend (as done with FastAPI) allows the application to handle multiple requests concurrently, which significantly improves throughput.

### Caching Responses:

  Redis Cache: Storing review results in Redis reduces repetitive API calls to OpenAI or GitHub. This would allow frequently requested reviews to be served from cache, improving response time and reducing API costs.
  Use a time-based expiration policy (e.g., 1 hour) to keep cache size manageable.

### Rate Limiting:

  Implement rate limiting to prevent abuse of the API and ensure stability. For example, allow 10 requests per minute per user to maintain fairness.

### Background Processing:

  Use a message queue like RabbitMQ or Celery for handling non-urgent or long-running tasks (e.g., fetching GitHub repositories or calling OpenAI API). This offloads work from the main application, improving responsiveness.

### Selective Analysis:

  Avoid analyzing all files in a repository. Instead, focus on files with certain extensions (e.g., .py, .js, .java) or within specific directories.
  Allow users to specify which files or folders to include in the review.

### Parallel File Processing:

  Process large repositories in parallel using Python's asyncio.gather or similar methods to fetch and analyze files concurrently.

### File Size and Complexity Limits:

  Set size and complexity limits for files to be analyzed (e.g., skip files larger than 1 MB or autogenerated code).
